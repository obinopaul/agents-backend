# Env
ENVIRONMENT='dev'

# Database
DATABASE_TYPE='postgresql'
DATABASE_HOST='127.0.0.1'
DATABASE_PORT=5432
DATABASE_USER='postgres'
DATABASE_PASSWORD='123456'

# Redis
REDIS_HOST='127.0.0.1'
REDIS_PORT=6379
REDIS_PASSWORD=''
REDIS_DATABASE=0

# Token
TOKEN_SECRET_KEY='1VkVF75nsNABBjK_7-qz7GtzNy3AMvktc9TCPwKczCk'
# Opera Log
OPERA_LOG_ENCRYPT_SECRET_KEY='d77b25790a804c2b4a339dd0207941e4cefa5751935a33735bc73bb7071a005b'
# [ App ] task
# Celery
CELERY_BROKER_REDIS_DATABASE=1
# Rabbitmq
CELERY_RABBITMQ_HOST='127.0.0.1'
CELERY_RABBITMQ_PORT=5672
CELERY_RABBITMQ_USERNAME='guest'
CELERY_RABBITMQ_PASSWORD='guest'
# [ Plugin ] oauth2
OAUTH2_GITHUB_CLIENT_ID='test'
OAUTH2_GITHUB_CLIENT_SECRET='test'
OAUTH2_GOOGLE_CLIENT_ID='test'
OAUTH2_GOOGLE_CLIENT_SECRET='test'
OAUTH2_LINUX_DO_CLIENT_ID='test'
OAUTH2_LINUX_DO_CLIENT_SECRET='test'
# [ Plugin ] email
EMAIL_USERNAME=''
EMAIL_PASSWORD=''

# ============================================================
# [ Module ] Agent - LangChain/LangGraph AI Agents
# ============================================================

# --------------------------------------------------------------------------
# [Robust Agent Configuration]
# --------------------------------------------------------------------------

# Basic Model (LLM) - The primary model for chat and planning
# Supports OpenAI-compatible endpoints (Doubao, OpenAI, vLLM, etc.)
BASIC_MODEL_BASE_URL="https://ark.cn-beijing.volces.com/api/v3"
BASIC_MODEL_NAME="doubao-1-5-pro-32k-250115"
BASIC_MODEL_API_KEY="xxxx"
BASIC_MODEL_MAX_RETRIES=3
BASIC_MODEL_TOKEN_LIMIT=200000 # Max input tokens for context compression (prevents overflow)
BASIC_MODEL_VERIFY_SSL=True    # Set to False if using self-signed certs

# Reasoning Model (Optional)
# Specialized model for complex "Deep Thinking" tasks (e.g., DeepSeek R1, Doubao Thinking)
REASONING_MODEL_BASE_URL="https://ark.cn-beijing.volces.com/api/v3"
REASONING_MODEL_NAME="doubao-1-5-thinking-pro-m-250428"
REASONING_MODEL_API_KEY="xxxx"
REASONING_MODEL_MAX_RETRIES=3
REASONING_MODEL_TOKEN_LIMIT=150000

# Provider API Keys (Fallbacks)
# These are used if you don't configure BASIC_MODEL, or for specific provider features
OPENAI_API_KEY=''
OPENAI_API_BASE=''
ANTHROPIC_API_KEY=''
AZURE_OPENAI_API_KEY=''
AZURE_OPENAI_ENDPOINT=''
AZURE_OPENAI_API_VERSION='2024-02-15-preview'
GOOGLE_API_KEY=''
TOGETHER_API_KEY=''
DEEPSEEK_API_KEY=''
DASHSCOPE_API_KEY=''

# Agent Workflow Configuration
AGENT_RECURSION_LIMIT=30          # Safety limit for maximum graph steps
AGENT_MAX_PLAN_ITERATIONS=1       # How many times the planner can revise its plan
AGENT_MAX_STEP_NUM=3              # Max steps execution per plan
AGENT_MAX_SEARCH_RESULTS=3        # Max results to fetch per search query
AGENT_ENABLE_DEEP_THINKING=False   # Enable usage of REASONING_MODEL if configured
AGENT_ENABLE_CLARIFICATION=False   # Allow agent to ask clarifying questions before starting
AGENT_MAX_CLARIFICATION_ROUNDS=3
AGENT_ENFORCE_WEB_SEARCH=False     # Force web search in every plan
AGENT_ENFORCE_RESEARCHER_SEARCH=True # Force researcher agent to use search tool

# Python REPL Sandbox (WARNING: Security Risk)
# Enable only in trusted environments (e.g., Docker container). Allows generating charts/math.
ENABLE_PYTHON_REPL=False

# Tool Interrupts (Human-in-the-loop)
# Comma-separated list of tools to require approval for before execution
# TOOL_INTERRUPTS_BEFORE="db_write_tool,payment_api"

# --------------------------------------------------------------------------
# [Search & Crawler]
# --------------------------------------------------------------------------
# Search Engine Selection: tavily, infoquest, duckduckgo, brave, bing, searx
AGENT_SEARCH_ENGINE=tavily
TAVILY_API_KEY=tvly-xxx
INFOQUEST_API_KEY="infoquest-xxx"
BRAVE_SEARCH_API_KEY=""
BING_SEARCH_API_KEY=""
JINA_API_KEY="jina_xxx"
SEARX_HOST=""

# Detailed Search Config
SEARCH_ENGINE_INCLUDE_DOMAINS=""      # Limit search to specific domains (comma-separated)
SEARCH_ENGINE_EXCLUDE_DOMAINS=""      # Exclude specific domains
SEARCH_ENGINE_SEARCH_DEPTH="advanced" # "basic" or "advanced"
SEARCH_ENGINE_INCLUDE_ANSWER=False    # Include an AI-generated direct answer in results
SEARCH_ENGINE_INCLUDE_RAW_CONTENT=True # Fetch full page content
SEARCH_ENGINE_INCLUDE_IMAGES=True
SEARCH_ENGINE_INCLUDE_IMAGE_DESCRIPTIONS=True
SEARCH_ENGINE_MIN_SCORE_THRESHOLD=0.0
SEARCH_ENGINE_MAX_CONTENT_LENGTH=4000 # Max chars per page result

# InfoQuest Specific Settings
SEARCH_ENGINE_TIME_RANGE=30           # Limit search to last N days
SEARCH_ENGINE_SITE=""                 # Site filter

# Crawler Engine (jina or infoquest)
# Used to fetch detailed content from URLs found in search
CRAWLER_ENGINE=jina
CRAWLER_FETCH_TIME=10                 # Wait time after page load (seconds)
CRAWLER_TIMEOUT=30                    # Overall timeout (seconds)
CRAWLER_NAVI_TIMEOUT=15               # Navigation timeout (seconds)

# --------------------------------------------------------------------------
# [RAG Providers]
# --------------------------------------------------------------------------
# Selection: milvus, qdrant, vikingdb, ragflow, dify, moi
AGENT_RAG_PROVIDER=milvus

# Embeddings (Shared)
EMBEDDING_PROVIDER="openai" # openai, dashscope
EMBEDDING_BASE_URL=""
EMBEDDING_MODEL="text-embedding-ada-002"
EMBEDDING_API_KEY=""
AUTO_LOAD_EXAMPLES=True     # Auto-load RAG examples into DB on startup

# Milvus Configuration
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_COLLECTION="agent_documents"

# Qdrant Configuration
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_API_KEY=""
QDRANT_COLLECTION="agent_documents"

# RagFlow Configuration
RAGFLOW_API_URL="http://localhost:9388"
RAGFLOW_API_KEY="ragflow-xxx"
RAGFLOW_RETRIEVAL_SIZE=10

# Dify Configuration
DIFY_API_URL="https://api.dify.ai/v1"
DIFY_API_KEY="dataset-xxx"

# VikingDB Configuration
VIKINGDB_KNOWLEDGE_BASE_API_URL=""
VIKINGDB_KNOWLEDGE_BASE_API_AK=""
VIKINGDB_KNOWLEDGE_BASE_API_SK=""
VIKINGDB_KNOWLEDGE_BASE_RETRIEVAL_SIZE=15

# MatrixOne (MOI) Configuration
MOI_API_URL=""
MOI_API_KEY=""
MOI_RETRIEVAL_SIZE=10
MOI_LIST_LIMIT=10

# --------------------------------------------------------------------------
# [Persistence & Production]
# --------------------------------------------------------------------------
# LangGraph Checkpointer (Conversation Memory)
LANGGRAPH_CHECKPOINT_ENABLED=True
# Database Connection String for persistence (Postgres recommended for production)
LANGGRAPH_CHECKPOINT_DB_URL='postgresql://postgres:123456@127.0.0.1:5432/fba'
# Set to 'True' in production to use Alembic migrations instead of auto-creating tables
AGENT_SKIP_DB_SETUP=False

# --------------------------------------------------------------------------
# [Other Services]
# --------------------------------------------------------------------------
# TTS (Text-to-Speech) - Volcengine
VOLCENGINE_TTS_APPID=''
VOLCENGINE_TTS_ACCESS_TOKEN=''
VOLCENGINE_TTS_CLUSTER='volcano_tts'
VOLCENGINE_TTS_VOICE_TYPE='BV700_V2_streaming'

# Agent API CORS
AGENT_ALLOWED_ORIGINS='http://localhost:3000'

# Agent Report Styles
AGENT_DEFAULT_REPORT_STYLE='ACADEMIC'


# --------------------------------------------------------------------------
# [Other Services]
# --------------------------------------------------------------------------
# Daytona Sandbox
DAYTONA_API_KEY=your_daytona_api_key_here
ALPHA_VANTAGE_API_KEY=your_alpha_vantage_api_key_here

# MCP Server Credentials
GITHUB_TOKEN=your_github_token_here
TAVILY_API_KEY=your_tavily_api_key_here

# LangSmith Tracing (Optional)
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGSMITH_PROJECT=your_langsmith_project_here


# =============================================================================
# Cloud Storage Credentials
# Provider is configured in config.yaml (storage.provider)
# =============================================================================

# -----------------------------------------------------------------------------
# AWS S3 Configuration
# -----------------------------------------------------------------------------
# AWS_ACCESS_KEY_ID=your_aws_access_key_id_here
# AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key_here
# S3_BUCKET_NAME=your_s3_bucket_name_here
# S3_REGION=us-east-1
# # Optional: CloudFront URL for faster delivery
# # S3_PUBLIC_URL_BASE=https://d1234.cloudfront.net

# -----------------------------------------------------------------------------
# Cloudflare R2
# -----------------------------------------------------------------------------
R2_ACCOUNT_ID=your_r2_account_id_here
R2_ACCESS_KEY_ID=your_r2_access_key_id_here
R2_SECRET_ACCESS_KEY=your_r2_secret_access_key_here
R2_BUCKET_NAME=your_r2_bucket_name_here
# Optional: Custom domain for public URLs (otherwise uses r2.dev)
# R2_PUBLIC_URL_BASE=https://cdn.yourdomain.com

# -----------------------------------------------------------------------------
# Alibaba Cloud OSS
# -----------------------------------------------------------------------------
# OSS_ACCESS_KEY_ID=your_oss_access_key_id_here
# OSS_ACCESS_KEY_SECRET=your_oss_access_key_secret_here
# OSS_BUCKET_NAME=your_oss_bucket_name_here
# OSS_REGION=oss-cn-hangzhou
# OSS_ENDPOINT=oss-cn-hangzhou.aliyuncs.com
# OSS_MAX_UPLOAD_SIZE=10485760
