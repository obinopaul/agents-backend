"""
Loop Detection Agent that extends LlmAgent with repetition detection.

This module provides a custom LlmAgent subclass that monitors streaming responses
for repetitive patterns and stops generation when loops are detected.
"""

import logging
import re
from typing import AsyncGenerator, Dict, List, Optional, Tuple

from google.adk.agents import InvocationContext, LlmAgent
from google.adk.events import Event
from google.genai import types
from pydantic import Field, PrivateAttr
from typing_extensions import override


logger = logging.getLogger(__name__)


class LoopDetectionAgent(LlmAgent):
    """
    LlmAgent subclass with loop detection for streaming responses.

    Monitors partial events during streaming and detects repetitive patterns.
    When a loop is detected, it stops the current agent to prevent infinite generation,
    but allows the workflow to continue with other agents.

    IMPORTANT: Loop detection only applies to content generated by THIS specific agent,
    not to events from sub-agents or tool agents that flow through this agent. This
    prevents false positives when sub-agents generate repetitive content.

    The detection thresholds are set conservatively to avoid false positives from
    normal repetitive content like file paths or code patterns. Only truly repetitive
    loops (5+ repetitions of 200+ character patterns) will trigger detection.
    """

    # Loop detection configuration (model fields so Pydantic allows assignment)
    min_pattern_length: int = Field(
        default=200,  # Increased from 50 to avoid triggering on file paths
        ge=1,
        description="Minimum characters for a candidate repeated pattern",
    )
    max_pattern_length: int = Field(
        default=1000,  # Increased from 500 for longer patterns
        ge=1,
        description="Maximum characters to consider for a candidate repeated pattern",
    )
    repetition_threshold: int = Field(
        default=5,  # Increased from 3 to be more lenient
        ge=2,
        description="Number of consecutive repetitions required to trigger loop detection",
    )
    window_size: int = Field(
        default=5000,  # Increased to accommodate larger patterns
        ge=100,
        description="Size of the sliding content window to analyze for loops",
    )

    # Internal state (private attrs are excluded from Pydantic field validation)
    _content_buffer: str = PrivateAttr(default="")
    _pattern_cache: Dict[str, int] = PrivateAttr(default_factory=dict)
    _loop_detected: bool = PrivateAttr(default=False)
    _last_patterns: List[str] = PrivateAttr(default_factory=list)
    _event_count: int = PrivateAttr(default=0)
    _partial_buffer: str = PrivateAttr(default="")

    def _reset_detection_state(self):
        """Reset the loop detection state for a new invocation."""
        self._content_buffer = ""
        self._pattern_cache = {}
        self._loop_detected = False
        self._last_patterns = []
        self._event_count = 0
        self._partial_buffer = ""

    def _maybe_save_output_to_state(self, event: Event) -> None:
        """
        Safely save output to state using parent class method.

        This wraps the parent class's private method with proper error handling.
        We need to call the parent's state-saving logic to maintain consistency
        with LlmAgent behavior, but use name mangling carefully as this is a
        private API that may change.

        Parameters
        ----------
        event : Event
            The event to potentially save to state
        """
        try:
            # Try to call the parent's private method using name mangling
            # This is necessary because we override _run_async_impl and need to
            # maintain the same state-saving behavior as the parent class
            if hasattr(self, '_LlmAgent__maybe_save_output_to_state'):
                self._LlmAgent__maybe_save_output_to_state(event)
            else:
                # Fallback: log a warning if the method doesn't exist
                # This prevents crashes if LlmAgent's internal API changes
                logger.debug(
                    f"[{self.name}] Parent class state-saving method not found (LlmAgent API may have changed)"
                )
        except AttributeError as e:
            logger.warning(f"[{self.name}] Could not save output to state: {e}")
        except Exception as e:
            logger.error(f"[{self.name}] Error saving output to state: {e}", exc_info=True)

    def _extract_text_from_event(self, event: Event) -> str:
        """Extract text content from an event."""
        if not event.content or not hasattr(event.content, 'parts'):
            return ""

        text_parts = []
        for part in event.content.parts:
            if hasattr(part, 'text') and part.text:
                text_parts.append(part.text)

        return "".join(text_parts)

    def _detect_pattern_repetition(self, text: str) -> Tuple[bool, Optional[str]]:
        """
        Optimized pattern detection - check smallest patterns first.

        Key insight: If a long pattern repeats N times, shorter patterns
        repeat more times. So we check from smallest to largest and exit
        as soon as we find ANY valid repetition.

        Time complexity: O(NÂ²) worst case, but O(N) best case when loops exist

        Returns:
            Tuple of (loop_detected, repeated_pattern)
        """
        if len(text) < self.min_pattern_length * self.repetition_threshold:
            return False, None

        # Clean text for pattern detection (remove extra whitespace)
        clean_text = re.sub(r'\s+', ' ', text).strip()
        text_len = len(clean_text)

        # Maximum feasible pattern length
        max_pattern = min(text_len // self.repetition_threshold, self.max_pattern_length)

        # CHECK FROM SMALLEST TO LARGEST - exit on first match!
        # This is key: we don't need to find the "best" pattern, just ANY pattern
        for pattern_len in range(self.min_pattern_length, max_pattern + 1):
            # For each length, scan through the text
            # Use sliding window with optimization for large texts
            step = 1 if text_len < 2000 else pattern_len // 4
            step = max(1, step)

            for start in range(0, text_len - pattern_len * self.repetition_threshold + 1, step):
                pattern = clean_text[start : start + pattern_len]

                # Count consecutive repetitions from this position
                count = 0
                pos = start

                while pos + pattern_len <= text_len and clean_text[pos : pos + pattern_len] == pattern:
                    count += 1
                    pos += pattern_len

                # Early exit on first valid pattern found!
                if count >= self.repetition_threshold:
                    logger.warning(f"Loop detected: Pattern of length {pattern_len} repeated {count} times")
                    return True, pattern[:100]

        return False, None

    def _parse_unknown_tool_error(self, exc: Exception) -> Tuple[bool, Optional[str]]:
        """Detect if an exception indicates an unknown tool function call.

        Parameters
        ----------
        exc : Exception
            The exception raised from the underlying ADK flow.

        Returns
        -------
        Tuple[bool, Optional[str]]
            A tuple where the first element indicates whether this is an
            unknown-tool error and the second element is the missing tool name
            if detected.
        """
        # ADK raises: "Function <name> is not found in the tools_dict."
        match = re.search(r"Function\s+([\w\-.]+)\s+is\s+not\s+found\s+in\s+the\s+tools_dict", str(exc))
        if match:
            return True, match.group(1)
        return False, None

    @override
    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:
        """
        Override the async implementation to add loop detection.

        This monitors streaming events for repetitive patterns and stops
        the current agent if a loop is detected. The agent will terminate
        gracefully, allowing the workflow to continue with other agents
        rather than ending the entire process.
        """
        # Reset detection state for new invocation
        self._reset_detection_state()

        # Track if we're in streaming mode
        is_streaming = False
        accumulated_text = ""

        try:
            async for event in self._llm_flow.run_async(ctx):
                self._event_count += 1

                # Check if this is a partial event (streaming)
                is_partial = getattr(event, 'partial', False)
                if is_partial:
                    is_streaming = True

                # Only check for loops in events from THIS agent, not sub-agents
                is_own_event = getattr(event, 'author', None) == self.name

                # Extract text from event
                event_text = self._extract_text_from_event(event)

                if event_text and is_own_event:
                    # Accumulate text for pattern detection
                    if is_streaming and is_partial:
                        # For partial events, accumulate in buffer
                        self._partial_buffer += event_text
                        accumulated_text = self._content_buffer + self._partial_buffer
                    else:
                        # For complete events, add to main buffer
                        self._content_buffer += event_text
                        accumulated_text = self._content_buffer
                        self._partial_buffer = ""  # Clear partial buffer

                    # Only check for loops after accumulating enough content
                    if len(accumulated_text) > self.min_pattern_length * 2:
                        # Keep only recent content for analysis (sliding window)
                        if len(accumulated_text) > self.window_size:
                            accumulated_text = accumulated_text[-self.window_size :]
                            # Update the main buffer to prevent memory leak
                            self._content_buffer = accumulated_text

                        # Detect repetition patterns
                        loop_detected, pattern = self._detect_pattern_repetition(accumulated_text)

                        if loop_detected and not self._loop_detected:
                            self._loop_detected = True

                            # Log the detection
                            logger.error(f"ðŸ”„ Loop detected in {self.name} after {self._event_count} total events")
                            logger.error(f"Pattern sample: {pattern[:100]}..." if pattern else "Unknown pattern")

                            # Create a warning event to notify about the loop
                            warning_event = Event(
                                author=self.name,
                                content=types.Content(
                                    role="model",
                                    parts=[
                                        types.Part(
                                            text="\n\n[LOOP DETECTED] Stopping current agent execution due to repetitive output pattern.\n\n"
                                            "The current agent has been stopped to prevent infinite generation. "
                                            "The workflow will continue with the next agent or step."
                                        )
                                    ],
                                ),
                                partial=False,  # This is a complete message
                                turn_complete=True,  # Signal end of turn
                            )

                            # Save output if configured
                            self._maybe_save_output_to_state(warning_event)
                            yield warning_event

                            # Stop processing this agent only - do NOT set ctx.end_invocation
                            # This allows the workflow to continue with other agents
                            return

                # Process state saving for non-loop events
                self._maybe_save_output_to_state(event)

                # Yield the event upstream
                yield event

                # If this was a final event (not partial), update our main buffer
                if is_streaming and not is_partial and self._partial_buffer:
                    self._content_buffer += self._partial_buffer
                    self._partial_buffer = ""

                    # Trim buffer if too large
                    if len(self._content_buffer) > self.window_size:
                        self._content_buffer = self._content_buffer[-self.window_size :]
        except Exception as e:
            is_unknown_tool, missing_tool = self._parse_unknown_tool_error(e)
            if not is_unknown_tool:
                raise

            # Try to list allowed tool names for helpful guidance
            allowed_names: List[str] = []
            try:
                tools = await self.canonical_tools(ctx)
                allowed_names = [getattr(t, 'name', '') for t in tools if getattr(t, 'name', '')]
            except Exception:
                allowed_names = []

            allowed_str = ", ".join(allowed_names) if allowed_names else "(none)"
            msg = (
                f"[TOOL NOT FOUND] The tool '{missing_tool}' is not available.\n"
                f"Allowed tools: {allowed_str}.\n"
                "Do not invent tool names. Choose a valid tool or proceed without tools."
            )
            warning_event = Event(
                author=self.name,
                content=types.Content(
                    role="model",
                    parts=[types.Part(text=msg)],
                ),
                partial=False,
                turn_complete=True,
            )
            self._maybe_save_output_to_state(warning_event)
            yield warning_event
            return

    @override
    async def _run_live_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:
        """
        Override the live implementation to add loop detection.

        Similar to _run_async_impl but for live/interactive sessions.
        The agent will terminate gracefully when a loop is detected,
        allowing the workflow to continue rather than ending the entire process.
        """
        # Reset detection state for new invocation
        self._reset_detection_state()

        try:
            async for event in self._llm_flow.run_live(ctx):
                self._event_count += 1

                # Only check for loops in events from THIS agent, not sub-agents
                is_own_event = getattr(event, 'author', None) == self.name

                # Extract and check text
                event_text = self._extract_text_from_event(event)

                if event_text and is_own_event:
                    self._content_buffer += event_text

                    # Keep only recent content
                    if len(self._content_buffer) > self.window_size:
                        self._content_buffer = self._content_buffer[-self.window_size :]

                    # Detect loops
                    if len(self._content_buffer) > self.min_pattern_length * 2:
                        loop_detected, pattern = self._detect_pattern_repetition(self._content_buffer)

                        if loop_detected and not self._loop_detected:
                            self._loop_detected = True

                            logger.error(
                                f"ðŸ”„ Loop detected in {self.name} (live mode) after {self._event_count} total events"
                            )
                            logger.error(f"Pattern sample: {pattern[:100]}..." if pattern else "Unknown pattern")

                            # Create warning event
                            warning_event = Event(
                                author=self.name,
                                content=types.Content(
                                    role="model",
                                    parts=[
                                        types.Part(
                                            text="\n\n[LOOP DETECTED] Stopping current agent execution due to repetitive output.\n\n"
                                            "The current agent has been stopped to prevent infinite generation. "
                                            "The workflow will continue with the next agent or step."
                                        )
                                    ],
                                ),
                                turn_complete=True,
                            )

                            self._maybe_save_output_to_state(warning_event)
                            yield warning_event

                            # Stop processing this agent only - do NOT set ctx.end_invocation
                            # This allows the workflow to continue with other agents
                            return

                # Process normally
                self._maybe_save_output_to_state(event)
                yield event

                if ctx.end_invocation:
                    return
        except Exception as e:
            is_unknown_tool, missing_tool = self._parse_unknown_tool_error(e)
            if not is_unknown_tool:
                raise

            allowed_names: List[str] = []
            try:
                tools = await self.canonical_tools(ctx)
                allowed_names = [getattr(t, 'name', '') for t in tools if getattr(t, 'name', '')]
            except Exception:
                allowed_names = []

            allowed_str = ", ".join(allowed_names) if allowed_names else "(none)"
            msg = (
                f"[TOOL NOT FOUND] The tool '{missing_tool}' is not available.\n"
                f"Allowed tools: {allowed_str}.\n"
                "Do not invent tool names. Choose a valid tool or proceed without tools."
            )
            warning_event = Event(
                author=self.name,
                content=types.Content(
                    role="model",
                    parts=[types.Part(text=msg)],
                ),
                turn_complete=True,
            )
            self._maybe_save_output_to_state(warning_event)
            yield warning_event
            return
